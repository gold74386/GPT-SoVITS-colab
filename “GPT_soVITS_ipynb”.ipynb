{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gold74386/GPT-SoVITS-colab/blob/main/%E2%80%9CGPT_soVITS_ipynb%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtOtTFiGZJ-N"
      },
      "source": [
        "## 0. 初始化检查"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maUJ4mNpYxxQ",
        "outputId": "d25711dc-c5dc-4fd8-bdbf-0b01878ad091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default GPU Device Details: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device Details: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIgovmIrZVAc"
      },
      "source": [
        "## 1. 挂载谷歌云盘"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMytosXDZUMg",
        "outputId": "0705e80b-e65f-4b47-9a1f-a98c7eb37dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66ri0484Yz64"
      },
      "source": [
        "## 2. 克隆最新仓库下载依赖配置环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rGL8TjVsjUD",
        "outputId": "64d7eb79-f58a-41eb-e20b-0f999a5dbb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GPT-SoVITS'...\n",
            "remote: Enumerating objects: 1542, done.\u001b[K\n",
            "remote: Counting objects: 100% (784/784), done.\u001b[K\n",
            "remote: Compressing objects: 100% (370/370), done.\u001b[K\n",
            "remote: Total 1542 (delta 526), reused 594 (delta 401), pack-reused 758\u001b[K\n",
            "Receiving objects: 100% (1542/1542), 2.84 MiB | 11.60 MiB/s, done.\n",
            "Resolving deltas: 100% (800/800), done.\n",
            "/content/GPT-SoVITS/GPT-SoVITS\n",
            "Cloning into 'GPT_SoVITS/pretrained_models'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 20 (delta 1), reused 0 (delta 0), pack-reused 4\u001b[K\n",
            "Unpacking objects: 100% (20/20), 102.34 KiB | 3.41 MiB/s, done.\n",
            "Filtering content: 100% (5/5), 1.11 GiB | 44.67 MiB/s, done.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.15.1)\n",
            "Requirement already satisfied: librosa==0.9.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.9.2)\n",
            "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.56.4)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.1.4)\n",
            "Requirement already satisfied: gradio==3.38.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.38.0)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.66.1)\n",
            "Requirement already satisfied: funasr>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.0.5)\n",
            "Requirement already satisfied: cn2an in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.5.22)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.50.0)\n",
            "Requirement already satisfied: pyopenjtalk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.3.3)\n",
            "Requirement already satisfied: g2p_en in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.1.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.1.0+cu121)\n",
            "Requirement already satisfied: modelscope==1.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (1.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (4.35.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (5.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (6.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (5.9.5)\n",
            "Requirement already satisfied: jieba_fast in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (0.53)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (0.42.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (23.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->-r requirements.txt (line 5)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.56.4->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (23.2.1)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (3.9.3)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.109.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.3.1)\n",
            "Requirement already satisfied: gradio-client>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.20.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (2.1.4)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.3.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (3.9.12)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (1.10.14)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.0.6)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (0.27.0.post1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.38.0->-r requirements.txt (line 7)) (11.0.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (23.2.0)\n",
            "Requirement already satisfied: datasets>=2.14.5 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (2.16.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: filelock>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (3.13.1)\n",
            "Requirement already satisfied: gast>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (0.5.4)\n",
            "Requirement already satisfied: oss2 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (2.18.4)\n",
            "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (2.8.2)\n",
            "Requirement already satisfied: simplejson>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (3.19.2)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (2.4.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (2.0.7)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 17)) (0.40.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.20.3)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.0.1)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 6)) (2.1.0+cu121)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 6)) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 6)) (1.3.0.post0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 6)) (0.10.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python->-r requirements.txt (line 8)) (0.18.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 9)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 9)) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 9)) (1.12)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: kaldiio>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (2.18.0)\n",
            "Requirement already satisfied: torch-complex in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (0.4.3)\n",
            "Requirement already satisfied: pytorch-wpe in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (0.0.1)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (0.6.2)\n",
            "Requirement already satisfied: hdbscan in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (0.8.33)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (0.5.5)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (0.3.4)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from funasr>=1.0.0->-r requirements.txt (line 11)) (1.3.2)\n",
            "Requirement already satisfied: proces>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from cn2an->-r requirements.txt (line 12)) (0.1.7)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p_en->-r requirements.txt (line 15)) (3.8.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from g2p_en->-r requirements.txt (line 15)) (7.0.0)\n",
            "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from g2p_en->-r requirements.txt (line 15)) (0.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning->-r requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning->-r requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 19)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 19)) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 19)) (0.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.38.0->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.38.0->-r requirements.txt (line 7)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.38.0->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 17)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 17)) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 17)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 17)) (0.70.15)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.3.2->funasr>=1.0.0->-r requirements.txt (line 11)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.3.2->funasr>=1.0.0->-r requirements.txt (line 11)) (4.9.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.38.0->-r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.38.0->-r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.38.0->-r requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en->-r requirements.txt (line 15)) (8.1.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.38.0->-r requirements.txt (line 7)) (2023.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.2->-r requirements.txt (line 4)) (4.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.38.0->-r requirements.txt (line 7)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.38.0->-r requirements.txt (line 7)) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.38.0->-r requirements.txt (line 7)) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.2->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.38.0->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime->-r requirements.txt (line 9)) (10.0)\n",
            "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.38.0->-r requirements.txt (line 7)) (0.35.1)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan->funasr>=1.0.0->-r requirements.txt (line 11)) (0.29.37)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.38.0->-r requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.38.0->-r requirements.txt (line 7)) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.38.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2->modelscope==1.10.0->-r requirements.txt (line 17)) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /usr/local/lib/python3.10/dist-packages (from oss2->modelscope==1.10.0->-r requirements.txt (line 17)) (3.20.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2->modelscope==1.10.0->-r requirements.txt (line 17)) (2.16.2)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2->modelscope==1.10.0->-r requirements.txt (line 17)) (2.14.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->-r requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn->funasr>=1.0.0->-r requirements.txt (line 11)) (0.5.11)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->modelscope==1.10.0->-r requirements.txt (line 17)) (7.0.1)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->modelscope==1.10.0->-r requirements.txt (line 17)) (2.0.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.10.0->-r requirements.txt (line 17)) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.10.0->-r requirements.txt (line 17)) (42.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->modelscope==1.10.0->-r requirements.txt (line 17)) (3.17.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.38.0->-r requirements.txt (line 7)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.38.0->-r requirements.txt (line 7)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.38.0->-r requirements.txt (line 7)) (0.17.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.38.0->-r requirements.txt (line 7)) (1.0.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.38.0->-r requirements.txt (line 7)) (1.2.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsox-dev is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0) (0.18.3)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n",
        "%cd GPT-SoVITS/\n",
        "!rm -rf GPT_SoVITS/pretrained_models  # 删除目标文件夹\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS GPT_SoVITS/pretrained_models  # 克隆仓库\n",
        "!pip install -r requirements.txt\n",
        "!sudo apt install ffmpeg\n",
        "!sudo apt install libsox-dev\n",
        "!pip install ffmpeg-python==0.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZRVt9Kbcrma"
      },
      "source": [
        "## 3. 启动！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZaH3db1cqtl",
        "outputId": "f5bc0b64-e36e-4a4f-d37c-7e67bd356c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on local URL:  http://0.0.0.0:9874\n",
            "Running on public URL: https://602a9d46c5414275fa.gradio.live\n",
            "\"/usr/bin/python3\" tools/slice_audio.py \"/content/GPT-SoVITS/vice/kd.wav\" \"output/slicer_opt/rme\" -34 4000 300 10 500 0.9 0.25 0 1\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/bin/python3\" tools/damo_asr/cmd-asr.py \"/content/GPT-SoVITS/GPT-SoVITS/output/slicer_opt/rme\"\n",
            "Please install rotary_embedding_torch by: \n",
            " pip install -U rotary_embedding_torch\n",
            "Please install rotary_embedding_torch by: \n",
            " pip install -U rotary_embedding_torch\n",
            "Please install rotary_embedding_torch by: \n",
            " pip install -U rotary_embedding_torch\n",
            "Please install rotary_embedding_torch by: \n",
            " pip install -U rotary_embedding_torch\n",
            "2024-02-02 13:01:07,890 - modelscope - INFO - PyTorch version 2.1.0+cu121 Found.\n",
            "2024-02-02 13:01:07,892 - modelscope - INFO - TensorFlow version 2.15.0 Found.\n",
            "2024-02-02 13:01:07,892 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
            "2024-02-02 13:01:07,892 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
            "2024-02-02 13:01:07,947 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 5c953683ca1e0798fc59e41c746f776b and a total number of 946 components indexed\n",
            "2024-02-02 13:01:09,572 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 10.9k/10.9k [00:00<00:00, 41.6MB/s]\n",
            "Downloading: 100% 173k/173k [00:00<00:00, 3.20MB/s]\n",
            "Downloading: 100% 2.45k/2.45k [00:00<00:00, 14.4MB/s]\n",
            "Downloading: 100% 472/472 [00:00<00:00, 2.28MB/s]\n",
            "Downloading: 100% 840M/840M [00:07<00:00, 112MB/s]\n",
            "Downloading: 100% 19.1k/19.1k [00:00<00:00, 1.08MB/s]\n",
            "Downloading: 100% 7.90M/7.90M [00:00<00:00, 41.0MB/s]\n",
            "Downloading: 100% 48.7k/48.7k [00:00<00:00, 1.44MB/s]\n",
            "Downloading: 100% 91.5k/91.5k [00:00<00:00, 2.62MB/s]\n",
            "2024-02-02 13:01:35,996 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 7.85k/7.85k [00:00<00:00, 29.0MB/s]\n",
            "Downloading: 100% 1.19k/1.19k [00:00<00:00, 5.96MB/s]\n",
            "Downloading: 100% 365/365 [00:00<00:00, 2.05MB/s]\n",
            "Downloading: 100% 1.64M/1.64M [00:00<00:00, 13.5MB/s]\n",
            "Downloading: 100% 8.45k/8.45k [00:00<00:00, 28.0MB/s]\n",
            "Downloading: 100% 27.3k/27.3k [00:00<00:00, 1.45MB/s]\n",
            "Downloading: 100% 2.16M/2.16M [00:00<00:00, 16.6MB/s]\n",
            "2024-02-02 13:01:45,444 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 6.00k/6.00k [00:00<00:00, 18.3MB/s]\n",
            "Downloading: 100% 810/810 [00:00<00:00, 4.17MB/s]\n",
            "Downloading: 100% 373/373 [00:00<00:00, 1.08MB/s]\n",
            "Downloading: 100% 278M/278M [00:02<00:00, 120MB/s]\n",
            "Downloading: 100% 863/863 [00:00<00:00, 4.87MB/s]\n",
            "Downloading: 100% 11.2k/11.2k [00:00<00:00, 33.5MB/s]\n",
            "Downloading: 100% 151k/151k [00:00<00:00, 2.84MB/s]\n",
            "Downloading: 100% 4.01M/4.01M [00:00<00:00, 26.8MB/s]\n",
            "rtf_avg: 0.099: 100% 1/1 [00:00<00:00,  1.76it/s]\n",
            "time cost vad: 0.567\n",
            "rtf_avg: 0.258, time_speech:  5.720, time_escape: 1.476: 100% 1/1 [00:01<00:00,  1.49s/it]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 20.13it/s]\n",
            "time cost vad: 0.050\n",
            "rtf_avg: 0.028, time_speech:  4.180, time_escape: 0.116: 100% 1/1 [00:00<00:00,  7.83it/s]\n",
            "rtf_avg: 0.010: 100% 1/1 [00:00<00:00,  5.71it/s]\n",
            "time cost vad: 0.175\n",
            "rtf_avg: 0.010, time_speech:  17.610, time_escape: 0.181: 100% 1/1 [00:00<00:00,  4.96it/s]\n",
            "rtf_avg: 0.011: 100% 1/1 [00:00<00:00,  8.39it/s]\n",
            "time cost vad: 0.120\n",
            "rtf_avg: 0.018, time_speech:  10.930, time_escape: 0.192: 100% 1/1 [00:00<00:00,  4.79it/s]\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 17.32it/s]\n",
            "time cost vad: 0.058\n",
            "rtf_avg: 0.023, time_speech:  4.230, time_escape: 0.096: 100% 1/1 [00:00<00:00,  9.16it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 14.96it/s]\n",
            "time cost vad: 0.067\n",
            "rtf_avg: 0.022, time_speech:  5.420, time_escape: 0.118: 100% 1/1 [00:00<00:00,  7.53it/s]\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 13.32it/s]\n",
            "time cost vad: 0.075\n",
            "rtf_avg: 0.020, time_speech:  5.440, time_escape: 0.108: 100% 1/1 [00:00<00:00,  8.12it/s]\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 12.11it/s]\n",
            "time cost vad: 0.083\n",
            "rtf_avg: 0.017, time_speech:  6.410, time_escape: 0.110: 100% 1/1 [00:00<00:00,  7.84it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 10.67it/s]\n",
            "time cost vad: 0.094\n",
            "rtf_avg: 0.017, time_speech:  7.580, time_escape: 0.128: 100% 1/1 [00:00<00:00,  6.95it/s]\n",
            "rtf_avg: 0.011: 100% 1/1 [00:00<00:00, 11.50it/s]\n",
            "time cost vad: 0.087\n",
            "rtf_avg: 0.015, time_speech:  7.730, time_escape: 0.115: 100% 1/1 [00:00<00:00,  7.48it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 17.20it/s]\n",
            "time cost vad: 0.058\n",
            "rtf_avg: 0.020, time_speech:  4.900, time_escape: 0.096: 100% 1/1 [00:00<00:00,  9.23it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 21.81it/s]\n",
            "time cost vad: 0.046\n",
            "rtf_avg: 0.023, time_speech:  3.670, time_escape: 0.085: 100% 1/1 [00:00<00:00,  9.88it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 14.77it/s]\n",
            "time cost vad: 0.068\n",
            "rtf_avg: 0.018, time_speech:  5.790, time_escape: 0.104: 100% 1/1 [00:00<00:00,  8.56it/s]\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 15.71it/s]\n",
            "time cost vad: 0.064\n",
            "rtf_avg: 0.022, time_speech:  4.500, time_escape: 0.099: 100% 1/1 [00:00<00:00,  8.86it/s]\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 16.82it/s]\n",
            "time cost vad: 0.060\n",
            "rtf_avg: 0.022, time_speech:  4.310, time_escape: 0.095: 100% 1/1 [00:00<00:00,  8.91it/s]\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 22.27it/s]\n",
            "time cost vad: 0.045\n",
            "rtf_avg: 0.026, time_speech:  3.330, time_escape: 0.087: 100% 1/1 [00:00<00:00,  9.69it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 16.19it/s]\n",
            "time cost vad: 0.062\n",
            "rtf_avg: 0.018, time_speech:  5.360, time_escape: 0.099: 100% 1/1 [00:00<00:00,  8.95it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  9.68it/s]\n",
            "time cost vad: 0.104\n",
            "rtf_avg: 0.016, time_speech:  8.870, time_escape: 0.144: 100% 1/1 [00:00<00:00,  6.27it/s]\n",
            "rtf_avg: 0.011: 100% 1/1 [00:00<00:00, 10.45it/s]\n",
            "time cost vad: 0.096\n",
            "rtf_avg: 0.013, time_speech:  8.480, time_escape: 0.113: 100% 1/1 [00:00<00:00,  7.75it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  8.58it/s]\n",
            "time cost vad: 0.117\n",
            "rtf_avg: 0.014, time_speech:  9.600, time_escape: 0.139: 100% 1/1 [00:00<00:00,  6.45it/s]\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 12.57it/s]\n",
            "time cost vad: 0.080\n",
            "rtf_avg: 0.017, time_speech:  6.080, time_escape: 0.105: 100% 1/1 [00:00<00:00,  8.21it/s]\n",
            "rtf_avg: 0.010: 100% 1/1 [00:00<00:00, 11.29it/s]\n",
            "time cost vad: 0.089\n",
            "rtf_avg: 0.015, time_speech:  8.430, time_escape: 0.126: 100% 1/1 [00:00<00:00,  6.94it/s]\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 13.01it/s]\n",
            "time cost vad: 0.077\n",
            "rtf_avg: 0.019, time_speech:  6.060, time_escape: 0.114: 100% 1/1 [00:00<00:00,  7.77it/s]\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 19.44it/s]\n",
            "time cost vad: 0.052\n",
            "rtf_avg: 0.023, time_speech:  4.060, time_escape: 0.093: 100% 1/1 [00:00<00:00,  9.50it/s]\n",
            "rtf_avg: 0.011: 100% 1/1 [00:00<00:00,  9.27it/s]\n",
            "time cost vad: 0.108\n",
            "rtf_avg: 0.013, time_speech:  9.900, time_escape: 0.130: 100% 1/1 [00:00<00:00,  6.83it/s]\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 18.41it/s]\n",
            "time cost vad: 0.055\n",
            "rtf_avg: 0.023, time_speech:  3.970, time_escape: 0.092: 100% 1/1 [00:00<00:00,  9.54it/s]\n",
            "rtf_avg: 0.010: 100% 1/1 [00:00<00:00,  8.40it/s]\n",
            "time cost vad: 0.119\n",
            "rtf_avg: 0.012, time_speech:  11.480, time_escape: 0.139: 100% 1/1 [00:00<00:00,  6.40it/s]\n",
            "rtf_avg: 0.011: 100% 1/1 [00:00<00:00, 13.27it/s]\n",
            "time cost vad: 0.076\n",
            "rtf_avg: 0.014, time_speech:  6.640, time_escape: 0.094: 100% 1/1 [00:00<00:00,  9.16it/s]\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 15.53it/s]\n",
            "time cost vad: 0.065\n",
            "rtf_avg: 0.018, time_speech:  4.930, time_escape: 0.087: 100% 1/1 [00:00<00:00, 10.06it/s]\n",
            "rtf_avg: 0.015: 100% 1/1 [00:00<00:00, 14.62it/s]\n",
            "time cost vad: 0.069\n",
            "rtf_avg: 0.022, time_speech:  4.650, time_escape: 0.104: 100% 1/1 [00:00<00:00,  8.62it/s]\n",
            "rtf_avg: 0.010: 100% 1/1 [00:00<00:00,  7.31it/s]\n",
            "time cost vad: 0.137\n",
            "rtf_avg: 0.012, time_speech:  13.730, time_escape: 0.165: 100% 1/1 [00:00<00:00,  5.43it/s]\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 19.89it/s]\n",
            "time cost vad: 0.051\n",
            "rtf_avg: 0.023, time_speech:  4.040, time_escape: 0.091: 100% 1/1 [00:00<00:00,  9.58it/s]\n",
            "rtf_avg: 0.011: 100% 1/1 [00:00<00:00, 19.16it/s]\n",
            "time cost vad: 0.052\n",
            "rtf_avg: 0.028, time_speech:  4.610, time_escape: 0.128: 100% 1/1 [00:00<00:00,  7.10it/s]\n",
            "rtf_avg: 0.016: 100% 1/1 [00:00<00:00,  4.38it/s]\n",
            "time cost vad: 0.229\n",
            "rtf_avg: 0.015, time_speech:  14.500, time_escape: 0.214: 100% 1/1 [00:00<00:00,  4.08it/s]\n",
            "rtf_avg: 0.018: 100% 1/1 [00:00<00:00, 10.06it/s]\n",
            "time cost vad: 0.100\n",
            "rtf_avg: 0.025, time_speech:  5.360, time_escape: 0.134: 100% 1/1 [00:00<00:00,  6.38it/s]\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00, 12.81it/s]\n",
            "time cost vad: 0.078\n",
            "rtf_avg: 0.035, time_speech:  4.000, time_escape: 0.139: 100% 1/1 [00:00<00:00,  6.01it/s]\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00, 12.24it/s]\n",
            "time cost vad: 0.082\n",
            "rtf_avg: 0.031, time_speech:  4.090, time_escape: 0.125: 100% 1/1 [00:00<00:00,  6.88it/s]\n",
            "rtf_avg: 0.021: 100% 1/1 [00:00<00:00, 11.17it/s]\n",
            "time cost vad: 0.090\n",
            "rtf_avg: 0.028, time_speech:  4.160, time_escape: 0.118: 100% 1/1 [00:00<00:00,  7.09it/s]\n",
            "\"/usr/bin/python3\" tools/subfix_webui.py --load_list \"/content/GPT-SoVITS/GPT-SoVITS/output/asr_opt/rme.list\" --webui_port 9871 --is_share True\n",
            "/content/GPT-SoVITS/GPT-SoVITS/tools/subfix_webui.py:366: GradioUnusedKwargWarning: You have unused kwarg parameters in Button, please remove them: {'link': '?__theme=light'}\n",
            "  btn_theme_dark = gr.Button(\"Light Theme\", link=\"?__theme=light\", scale=1)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/tools/subfix_webui.py:367: GradioUnusedKwargWarning: You have unused kwarg parameters in Button, please remove them: {'link': '?__theme=dark'}\n",
            "  btn_theme_light = gr.Button(\"Dark Theme\", link=\"?__theme=dark\", scale=1)\n",
            "Running on local URL:  http://0.0.0.0:9871\n",
            "Running on public URL: https://fad81f77b15af24327.gradio.live\n",
            "\"/usr/bin/python3\" tools/subfix_webui.py --load_list \"/content/GPT-SoVITS/GPT-SoVITS/output/asr_opt/rme.list\" --webui_port 9871 --is_share True\n",
            "/content/GPT-SoVITS/GPT-SoVITS/tools/subfix_webui.py:366: GradioUnusedKwargWarning: You have unused kwarg parameters in Button, please remove them: {'link': '?__theme=light'}\n",
            "  btn_theme_dark = gr.Button(\"Light Theme\", link=\"?__theme=light\", scale=1)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/tools/subfix_webui.py:367: GradioUnusedKwargWarning: You have unused kwarg parameters in Button, please remove them: {'link': '?__theme=dark'}\n",
            "  btn_theme_light = gr.Button(\"Dark Theme\", link=\"?__theme=dark\", scale=1)\n",
            "Running on local URL:  http://0.0.0.0:9871\n",
            "Running on public URL: https://86b4119ec361c81cd1.gradio.live\n",
            "\"/usr/bin/python3\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/bin/python3\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
            "Building prefix dict from the default dictionary ...\n",
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /content/GPT-SoVITS/GPT-SoVITS/TEMP/jieba.cache\n",
            "Loading model cost 1.426 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "Dumping model to file cache /content/GPT-SoVITS/GPT-SoVITS/TEMP/jieba.cache\n",
            "Loading model cost 1.281 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "\"/usr/bin/python3\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/bin/python3\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "Some weights of the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertModel were not initialized from the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertModel were not initialized from the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\"/usr/bin/python3\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/bin/python3\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "<All keys matched successfully>\n",
            "<All keys matched successfully>\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "\"/usr/bin/python3\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/bin/python3\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "Some weights of the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_v', 'encoder.pos_conv_embed.conv.weight_g']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertModel were not initialized from the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_v', 'encoder.pos_conv_embed.conv.weight_g']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertModel were not initialized from the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\"/usr/bin/python3\" GPT_SoVITS/s2_train.py --config \"/content/GPT-SoVITS/GPT-SoVITS/TEMP/tmp_s2.json\"\n",
            "2024-02-02 13:19:20.421788: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:19:20.421859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:19:20.423238: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2024-02-02 13:19:21.869596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "2024-02-02 13:19:26.412631: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:19:26.412721: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:19:26.413943: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2024-02-02 13:19:27.526784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:ame:{'train': {'log_interval': 100, 'eval_interval': 500, 'seed': 1234, 'epochs': 8, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 7, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 20480, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0, 'text_low_lr_rate': 0.4, 'pretrained_s2G': 'GPT_SoVITS/pretrained_models/s2G488k.pth', 'pretrained_s2D': 'GPT_SoVITS/pretrained_models/s2D488k.pth', 'if_save_latest': True, 'if_save_every_weights': True, 'save_every_epoch': 4, 'gpu_numbers': '0'}, 'data': {'max_wav_value': 32768.0, 'sampling_rate': 32000, 'filter_length': 2048, 'hop_length': 640, 'win_length': 2048, 'n_mel_channels': 128, 'mel_fmin': 0.0, 'mel_fmax': None, 'add_blank': True, 'n_speakers': 300, 'cleaned_text': True, 'exp_dir': 'logs/ame'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [10, 8, 2, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 8, 2, 2], 'n_layers_q': 3, 'use_spectral_norm': False, 'gin_channels': 512, 'semantic_frame_rate': '25hz', 'freeze_quantizer': True}, 's2_ckpt_dir': 'logs/ame', 'content_module': 'cnhubert', 'save_weight_dir': 'SoVITS_weights', 'name': 'ame', 'pretrain': None, 'resume_step': None}\n",
            "phoneme_data_len: 38\n",
            "wav_data_len: 76\n",
            "100% 76/76 [00:00<00:00, 77786.02it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  76\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "ssl_proj.weight not requires_grad\n",
            "ssl_proj.bias not requires_grad\n",
            "INFO:ame:loaded pretrained GPT_SoVITS/pretrained_models/s2G488k.pth\n",
            "<All keys matched successfully>\n",
            "INFO:ame:loaded pretrained GPT_SoVITS/pretrained_models/s2D488k.pth\n",
            "<All keys matched successfully>\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "0it [00:00, ?it/s]2024-02-02 13:19:50.085196: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:19:50.085257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:19:50.096838: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-02 13:19:50.184210: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:19:50.184263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:19:50.185765: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-02 13:19:50.731810: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:19:50.731875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:19:50.733530: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-02 13:19:50.738467: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:19:50.745686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:19:50.747364: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-02 13:19:50.754948: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:19:50.754991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:19:50.756807: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-02 13:19:50.758047: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:19:50.761670: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:19:50.763235: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2024-02-02 13:19:55.565542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-02-02 13:19:55.714909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2024-02-02 13:19:56.220453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-02-02 13:19:56.587800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "2024-02-02 13:19:56.760551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-02-02 13:19:56.855707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "DEBUG:jax._src.path:etils.epath found. Using etils.epath for file I/O.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at ../aten/src/ATen/EmptyTensor.cpp:31.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:251: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
            "grad.sizes() = [1, 9, 96], strides() = [139296, 96, 1]\n",
            "bucket_view.sizes() = [1, 9, 96], strides() = [864, 96, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:320.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "INFO:ame:Train Epoch: 1 [0%]\n",
            "INFO:ame:[2.5181100368499756, 2.189713478088379, 7.786422252655029, 22.412641525268555, 0.6187403798103333, 1.9153633117675781, 0, 9.99875e-05]\n",
            "15it [00:59,  3.97s/it]\n",
            "INFO:ame:====> Epoch: 1\n",
            "15it [00:20,  1.39s/it]\n",
            "INFO:ame:====> Epoch: 2\n",
            "15it [00:21,  1.42s/it]\n",
            "INFO:ame:====> Epoch: 3\n",
            "15it [00:20,  1.38s/it]\n",
            "INFO:ame:Saving model and optimizer state at iteration 4 to logs/ame/logs_s2/G_233333333333.pth\n",
            "INFO:ame:Saving model and optimizer state at iteration 4 to logs/ame/logs_s2/D_233333333333.pth\n",
            "INFO:ame:saving ckpt ame_e4:Success.\n",
            "INFO:ame:====> Epoch: 4\n",
            "15it [00:21,  1.40s/it]\n",
            "INFO:ame:====> Epoch: 5\n",
            "15it [00:21,  1.41s/it]\n",
            "INFO:ame:====> Epoch: 6\n",
            "10it [00:17,  1.31it/s]INFO:ame:Train Epoch: 7 [67%]\n",
            "INFO:ame:[2.8626513481140137, 2.3223717212677, 7.343843460083008, 19.62527084350586, 0.5208959579467773, 1.4710156917572021, 100, 9.991253280566489e-05]\n",
            "15it [00:21,  1.45s/it]\n",
            "INFO:ame:====> Epoch: 7\n",
            "15it [00:21,  1.44s/it]\n",
            "INFO:ame:Saving model and optimizer state at iteration 8 to logs/ame/logs_s2/G_233333333333.pth\n",
            "INFO:ame:Saving model and optimizer state at iteration 8 to logs/ame/logs_s2/D_233333333333.pth\n",
            "INFO:ame:saving ckpt ame_e8:Success.\n",
            "INFO:ame:====> Epoch: 8\n",
            "\"/usr/bin/python3\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "[rank: 0] Seed set to 1234\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Missing logger folder: logs/ame/logs_s1/logs_s1\n",
            "2024-02-02 13:24:40.539119: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-02 13:24:40.539172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-02 13:24:40.542285: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-02 13:24:42.458112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "semantic_data_len: 38\n",
            "phoneme_data_len: 38\n",
            "                     item_name                                     semantic_audio\n",
            "0   kd.wav_2271360_2454400.wav  474 265 980 95 231 961 552 7 7 7 7 720 70 463 ...\n",
            "1   kd.wav_6285440_6848960.wav  365 539 101 869 306 70 92 92 101 306 148 965 1...\n",
            "2   kd.wav_4126400_4261760.wav  913 221 238 345 599 964 380 964 198 750 221 45...\n",
            "3   kd.wav_2097280_2271360.wav  134 203 581 103 208 515 227 214 623 921 66 462...\n",
            "4   kd.wav_5250880_5493440.wav  214 254 308 884 133 133 769 867 564 646 319 33...\n",
            "5   kd.wav_3039040_3195840.wav  1012 612 837 872 1017 208 14 58 1008 308 559 1...\n",
            "6   kd.wav_3195840_3381120.wav  1005 318 103 103 318 797 797 258 239 239 544 5...\n",
            "7   kd.wav_2771200_2909120.wav  1012 965 27 663 90 283 420 275 782 931 384 56 ...\n",
            "8     kd.wav_271040_442560.wav  582 921 504 902 504 256 953 565 90 257 393 120...\n",
            "9     kd.wav_442560_713920.wav  208 14 179 634 930 916 240 240 240 237 57 752 ...\n",
            "10  kd.wav_3381120_3575680.wav  208 185 565 593 844 844 16 185 656 160 160 620...\n",
            "11  kd.wav_1057280_1251200.wav  582 463 945 945 556 129 811 129 60 75 184 970 ...\n",
            "12  kd.wav_2454400_2771200.wav  913 721 203 75 3 577 989 393 547 37 657 132 6 ...\n",
            "13  kd.wav_1251200_1618560.wav  899 995 623 247 921 504 242 358 612 699 559 72...\n",
            "14  kd.wav_7641920_7799680.wav  612 2 504 25 52 227 27 1017 208 1017 921 634 6...\n",
            "15  kd.wav_5846080_6285440.wav  913 239 1017 404 404 127 177 16 837 500 576 78...\n",
            "16  kd.wav_3978880_4126400.wav  208 103 318 318 318 1005 318 208 318 318 1001 ...\n",
            "17  kd.wav_1925760_2097280.wav  208 16 177 762 565 8 783 513 393 414 614 512 2...\n",
            "18   kd.wav_926400_1057280.wav  208 318 631 86 661 37 205 655 755 755 863 369 ...\n",
            "19  kd.wav_7508160_7641920.wav  1012 539 844 687 127 127 500 134 272 762 453 5...\n",
            "20  kd.wav_5496320_5846080.wav  913 190 916 641 564 586 639 85 127 666 166 187...\n",
            "21  kd.wav_4261760_4435200.wav  872 404 752 634 27 90 90 760 780 764 527 355 2...\n",
            "22  kd.wav_4435200_4640320.wav  1005 775 965 539 55 546 674 945 166 187 80 674...\n",
            "23  kd.wav_6976960_7224320.wav  208 243 1005 208 318 516 203 476 555 747 631 8...\n",
            "24  kd.wav_3861440_3978880.wav  864 1017 90 762 916 237 2 2 2 57 752 57 750 99...\n",
            "25    kd.wav_127040_271040.wav  76 504 687 687 687 687 752 916 177 240 103 3 9...\n",
            "26  kd.wav_8094400_8200960.wav  520 105 280 520 486 280 280 280 280 105 271 72...\n",
            "27  kd.wav_7224320_7508160.wav  208 318 318 500 239 679 208 318 560 830 547 76...\n",
            "28  kd.wav_1618560_1925760.wav  214 2 134 995 746 722 185 27 154 982 27 598 37...\n",
            "29  kd.wav_3575680_3845440.wav  500 566 763 124 585 437 687 10 1014 764 134 10...\n",
            "30  kd.wav_2909120_3039040.wav  722 185 451 208 837 213 495 963 583 677 296 84...\n",
            "31         kd.wav_0_127040.wav  520 124 403 129 946 414 831 25 949 446 82 282 ...\n",
            "32    kd.wav_713920_926400.wav  872 16 177 127 99 598 203 612 921 544 516 145 ...\n",
            "33  kd.wav_7932800_8081600.wav  14 27 593 404 52 127 240 500 376 980 91 222 25...\n",
            "34  kd.wav_4651520_4780800.wav  1002 63 920 176 690 671 705 705 802 587 710 57...\n",
            "35  kd.wav_4786880_5250880.wav  23 451 318 718 942 549 251 803 962 863 264 324...\n",
            "36  kd.wav_6848960_6976960.wav  539 247 549 835 791 770 770 363 676 708 173 43...\n",
            "37  kd.wav_7799680_7932800.wav  208 90 515 910 166 730 265 93 731 467 544 676 ...\n",
            "dataset.__len__(): 76\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                 | Params\n",
            "-----------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.5 M\n",
            "-----------------------------------------------\n",
            "77.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.5 M    Total params\n",
            "309.975   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0:   0% 0/11 [00:00<?, ?it/s] /content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [469, 469], which does not match the required output shape [112, 469, 469]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [372, 372], which does not match the required output shape [112, 372, 372]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [299, 299], which does not match the required output shape [112, 299, 299]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [263, 263], which does not match the required output shape [112, 263, 263]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [316, 316], which does not match the required output shape [112, 316, 316]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [586, 586], which does not match the required output shape [112, 586, 586]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [280, 280], which does not match the required output shape [112, 280, 280]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [508, 508], which does not match the required output shape [112, 508, 508]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [348, 348], which does not match the required output shape [96, 348, 348]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 1:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=3.8e+3, lr_step=0.002, top_3_acc_step=0.174, total_loss_epoch=5.75e+3, lr_epoch=0.00421, top_3_acc_epoch=0.138]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [296, 296], which does not match the required output shape [112, 296, 296]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [279, 279], which does not match the required output shape [112, 279, 279]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [348, 348], which does not match the required output shape [112, 348, 348]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [194, 194], which does not match the required output shape [96, 194, 194]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 2:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=3.29e+3, lr_step=0.002, top_3_acc_step=0.148, total_loss_epoch=5.77e+3, lr_epoch=0.002, top_3_acc_epoch=0.139]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [374, 374], which does not match the required output shape [112, 374, 374]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [382, 382], which does not match the required output shape [112, 382, 382]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [289, 289], which does not match the required output shape [112, 289, 289]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [317, 317], which does not match the required output shape [112, 317, 317]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [586, 586], which does not match the required output shape [96, 586, 586]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 3:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=4.93e+3, lr_step=0.002, top_3_acc_step=0.133, total_loss_epoch=5.74e+3, lr_epoch=0.002, top_3_acc_epoch=0.137]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [262, 262], which does not match the required output shape [112, 262, 262]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [387, 387], which does not match the required output shape [112, 387, 387]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [253, 253], which does not match the required output shape [112, 253, 253]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [508, 508], which does not match the required output shape [96, 508, 508]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 4:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=5.69e+3, lr_step=0.002, top_3_acc_step=0.148, total_loss_epoch=5.73e+3, lr_epoch=0.002, top_3_acc_epoch=0.136]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [235, 235], which does not match the required output shape [112, 235, 235]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [274, 274], which does not match the required output shape [112, 274, 274]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [202, 202], which does not match the required output shape [96, 202, 202]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 5:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=3.6e+3, lr_step=0.002, top_3_acc_step=0.157, total_loss_epoch=5.75e+3, lr_epoch=0.002, top_3_acc_epoch=0.141]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [372, 372], which does not match the required output shape [96, 372, 372]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 7:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=5.28e+3, lr_step=0.002, top_3_acc_step=0.138, total_loss_epoch=5.53e+3, lr_epoch=0.002, top_3_acc_epoch=0.157]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [316, 316], which does not match the required output shape [96, 316, 316]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 8:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=3.27e+3, lr_step=0.002, top_3_acc_step=0.224, total_loss_epoch=5.36e+3, lr_epoch=0.002, top_3_acc_epoch=0.177]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [469, 469], which does not match the required output shape [96, 469, 469]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 9:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=4.79e+3, lr_step=0.002, top_3_acc_step=0.196, total_loss_epoch=5.17e+3, lr_epoch=0.002, top_3_acc_epoch=0.198]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [259, 259], which does not match the required output shape [112, 259, 259]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 10:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=4.31e+3, lr_step=0.002, top_3_acc_step=0.232, total_loss_epoch=5.03e+3, lr_epoch=0.002, top_3_acc_epoch=0.219]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [385, 385], which does not match the required output shape [112, 385, 385]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 13:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=3.49e+3, lr_step=0.002, top_3_acc_step=0.334, total_loss_epoch=4.53e+3, lr_epoch=0.002, top_3_acc_epoch=0.297]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [223, 223], which does not match the required output shape [112, 223, 223]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [296, 296], which does not match the required output shape [96, 296, 296]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 14:   0% 0/11 [00:00<?, ?it/s, v_num=0, total_loss_step=2.97e+3, lr_step=0.002, top_3_acc_step=0.383, total_loss_epoch=4.35e+3, lr_epoch=0.002, top_3_acc_epoch=0.331]/content/GPT-SoVITS/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py:133: UserWarning: An output with one or more elements was resized since it had shape [234, 234], which does not match the required output shape [112, 234, 234]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n",
            "Epoch 14: 100% 11/11 [00:02<00:00,  4.14it/s, v_num=0, total_loss_step=2.88e+3, lr_step=0.002, top_3_acc_step=0.402, total_loss_epoch=4.15e+3, lr_epoch=0.002, top_3_acc_epoch=0.361]`Trainer.fit` stopped: `max_epochs=15` reached.\n",
            "Epoch 14: 100% 11/11 [00:12<00:00,  1.12s/it, v_num=0, total_loss_step=2.88e+3, lr_step=0.002, top_3_acc_step=0.402, total_loss_epoch=4.15e+3, lr_epoch=0.002, top_3_acc_epoch=0.361]\n",
            "\"/usr/bin/python3\" GPT_SoVITS/inference_webui.py\n",
            "Some weights of the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertModel were not initialized from the model checkpoint at GPT_SoVITS/pretrained_models/chinese-hubert-base and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "<All keys matched successfully>\n",
            "Number of parameter: 77.49M\n",
            "Running on local URL:  http://0.0.0.0:9872\n",
            "Running on public URL: https://b844142b936019583e.gradio.live\n",
            "实际输入的参考文本: 今天呢我跟大家分享一个关于化妆包的话题。\n",
            "实际输入的目标文本: 滚滚长江东逝水，浪花淘尽英雄。\n",
            "\n",
            "是非成败转头空。\n",
            "\n",
            "青山依旧在，几度夕阳红。\n",
            "\n",
            "白发渔樵江渚上，惯看秋月春风。\n",
            "\n",
            "一壶浊酒喜相逢。\n",
            "\n",
            "古今多少事，都付笑谈中。\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba_fast:Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /content/GPT-SoVITS/GPT-SoVITS/TEMP/jieba.cache\n",
            "DEBUG:jieba_fast:Loading model from cache /content/GPT-SoVITS/GPT-SoVITS/TEMP/jieba.cache\n",
            "Loading model cost 0.700 seconds.\n",
            "DEBUG:jieba_fast:Loading model cost 0.700 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "DEBUG:jieba_fast:Prefix dict has been built succesfully.\n",
            "[]\n",
            "实际输入的目标文本(切句后): 滚滚长江东逝水，浪花淘尽英雄。\n",
            "是非成败转头空。\n",
            "青山依旧在，\n",
            "几度夕阳红。\n",
            "白发渔樵江渚上，惯看秋月春风。\n",
            "一壶浊酒喜相逢。\n",
            "古今多少事，都付笑谈中。\n",
            "['今天呢我跟大家分享一个关于化妆包的话题。']\n",
            "['zh']\n",
            "实际输入的目标文本(每句): 滚滚长江东逝水，浪花淘尽英雄。\n",
            "[]\n",
            "['滚滚长江东逝水，浪花淘尽英雄。']\n",
            "['zh']\n",
            "  8% 125/1500 [00:02<00:20, 66.59it/s]T2S Decoding EOS [114 -> 241]\n",
            "  8% 127/1500 [00:02<00:24, 57.16it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
            "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "实际输入的目标文本(每句): 是非成败转头空。\n",
            "[]\n",
            "['是非成败转头空。']\n",
            "['zh']\n",
            "  4% 55/1500 [00:00<00:30, 47.89it/s]T2S Decoding EOS [114 -> 169]\n",
            "  4% 55/1500 [00:01<00:26, 54.30it/s]\n",
            "实际输入的目标文本(每句): 青山依旧在，\n",
            "[]\n",
            "['青山依旧在，']\n",
            "['zh']\n",
            "  3% 47/1500 [00:00<00:31, 46.43it/s]T2S Decoding EOS [114 -> 161]\n",
            "  3% 47/1500 [00:00<00:30, 47.37it/s]\n",
            "实际输入的目标文本(每句): 几度夕阳红。\n",
            "[]\n",
            "['几度夕阳红。']\n",
            "['zh']\n",
            "  3% 38/1500 [00:00<00:24, 59.89it/s]T2S Decoding EOS [114 -> 152]\n",
            "  3% 38/1500 [00:00<00:25, 56.41it/s]\n",
            "实际输入的目标文本(每句): 白发渔樵江渚上，惯看秋月春风。\n",
            "[]\n",
            "['白发渔樵江渚上，惯看秋月春风。']\n",
            "['zh']\n",
            "  7% 105/1500 [00:01<00:21, 63.42it/s]T2S Decoding EOS [114 -> 220]\n",
            "  7% 106/1500 [00:01<00:21, 63.52it/s]\n",
            "实际输入的目标文本(每句): 一壶浊酒喜相逢。\n",
            "[]\n",
            "['一壶浊酒喜相逢。']\n",
            "['zh']\n",
            "  4% 57/1500 [00:00<00:21, 66.51it/s]T2S Decoding EOS [114 -> 171]\n",
            "  4% 57/1500 [00:00<00:22, 63.93it/s]\n",
            "实际输入的目标文本(每句): 古今多少事，都付笑谈中。\n",
            "[]\n",
            "['古今多少事，都付笑谈中。']\n",
            "['zh']\n",
            "  4% 55/1500 [00:00<00:21, 66.85it/s]T2S Decoding EOS [114 -> 174]\n",
            "  4% 60/1500 [00:00<00:22, 64.46it/s]\n",
            "1.881\t12.747\t0.932\t0.441\n",
            "实际输入的参考文本: 今天呢我跟大家分享一个关于化妆包的话题。\n",
            "实际输入的目标文本: 滚滚长江东逝水，浪花淘尽英雄。\n",
            "\n",
            "是非成败转头空。\n",
            "\n",
            "青山依旧在，几度夕阳红。\n",
            "\n",
            "白发渔樵江渚上，惯看秋月春风。\n",
            "\n",
            "一壶浊酒喜相逢。\n",
            "\n",
            "古今多少事，都付笑谈中。\n",
            "[]\n",
            "实际输入的目标文本(切句后): 滚滚长江东逝水，浪花淘尽英雄\n",
            "是非成败转头空\n",
            "青山依旧在，几度夕阳红\n",
            "白发渔樵江渚上，惯看秋月春风\n",
            "一壶浊酒喜相逢\n",
            "古今多少事，都付笑谈中\n",
            "['今天呢我跟大家分享一个关于化妆包的话题。']\n",
            "['zh']\n",
            "实际输入的目标文本(每句): 滚滚长江东逝水，浪花淘尽英雄.\n",
            "  0% 0/1500 [00:00<?, ?it/s]T2S Decoding EOS [114 -> 115]\n",
            "  0% 1/1500 [00:00<00:55, 26.82it/s]\n",
            "实际输入的目标文本(每句): 是非成败转头空.\n",
            "  0% 0/1500 [00:00<?, ?it/s]T2S Decoding EOS [114 -> 115]\n",
            "  0% 1/1500 [00:00<00:49, 30.31it/s]\n",
            "实际输入的目标文本(每句): 青山依旧在，几度夕阳红.\n",
            "  0% 0/1500 [00:00<?, ?it/s]T2S Decoding EOS [114 -> 115]\n",
            "  0% 1/1500 [00:00<00:54, 27.31it/s]\n",
            "实际输入的目标文本(每句): 白发渔樵江渚上，惯看秋月春风.\n",
            "  0% 0/1500 [00:00<?, ?it/s]T2S Decoding EOS [114 -> 115]\n",
            "  0% 1/1500 [00:00<00:46, 32.57it/s]\n",
            "实际输入的目标文本(每句): 一壶浊酒喜相逢.\n",
            "  0% 0/1500 [00:00<?, ?it/s]T2S Decoding EOS [114 -> 115]\n",
            "  0% 1/1500 [00:00<00:46, 31.98it/s]\n",
            "实际输入的目标文本(每句): 古今多少事，都付笑谈中.\n",
            "  0% 0/1500 [00:00<?, ?it/s]T2S Decoding EOS [114 -> 115]\n",
            "  0% 1/1500 [00:00<00:46, 32.04it/s]\n",
            "0.112\t1.466\t0.032\t0.179\n",
            "实际输入的参考文本: 今天呢我跟大家分享一个关于化妆包的话题。\n",
            "实际输入的目标文本: 滚滚长江东逝水，浪花淘尽英雄。\n",
            "\n",
            "是非成败转头空。\n",
            "\n",
            "青山依旧在，几度夕阳红。\n",
            "\n",
            "白发渔樵江渚上，惯看秋月春风。\n",
            "\n",
            "一壶浊酒喜相逢。\n",
            "\n",
            "古今多少事，都付笑谈中。\n",
            "[]\n",
            "实际输入的目标文本(切句后): 滚滚长江东逝水，浪花淘尽英雄\n",
            "是非成败转头空\n",
            "青山依旧在，几度夕阳红\n",
            "白发渔樵江渚上，惯看秋月春风\n",
            "一壶浊酒喜相逢\n",
            "古今多少事，都付笑谈中\n",
            "['今天呢我跟大家分享一个关于化妆包的话题。']\n",
            "['zh']\n",
            "实际输入的目标文本(每句): 滚滚长江东逝水，浪花淘尽英雄。\n",
            "[]\n",
            "['滚滚长江东逝水，浪花淘尽英雄。']\n",
            "['zh']\n",
            "  6% 94/1500 [00:02<00:33, 41.60it/s]T2S Decoding EOS [114 -> 212]\n",
            "  7% 98/1500 [00:02<00:30, 45.35it/s]\n",
            "实际输入的目标文本(每句): 是非成败转头空。\n",
            "[]\n",
            "['是非成败转头空。']\n",
            "['zh']\n",
            "  3% 49/1500 [00:01<00:35, 41.38it/s]T2S Decoding EOS [114 -> 165]\n",
            "  3% 51/1500 [00:01<00:36, 40.15it/s]\n",
            "实际输入的目标文本(每句): 青山依旧在，几度夕阳红。\n",
            "[]\n",
            "['青山依旧在，几度夕阳红。']\n",
            "['zh']\n",
            "  5% 77/1500 [00:01<00:22, 63.97it/s]T2S Decoding EOS [114 -> 196]\n",
            "  5% 82/1500 [00:01<00:22, 62.48it/s]\n",
            "实际输入的目标文本(每句): 白发渔樵江渚上，惯看秋月春风。\n",
            "[]\n",
            "['白发渔樵江渚上，惯看秋月春风。']\n",
            "['zh']\n",
            "  6% 91/1500 [00:01<00:22, 62.31it/s]T2S Decoding EOS [114 -> 211]\n",
            "  6% 97/1500 [00:01<00:22, 61.39it/s]\n",
            "实际输入的目标文本(每句): 一壶浊酒喜相逢。\n",
            "[]\n",
            "['一壶浊酒喜相逢。']\n",
            "['zh']\n",
            "  4% 63/1500 [00:01<00:23, 61.64it/s]T2S Decoding EOS [114 -> 182]\n",
            "  5% 68/1500 [00:01<00:23, 61.54it/s]\n",
            "实际输入的目标文本(每句): 古今多少事，都付笑谈中。\n",
            "[]\n",
            "['古今多少事，都付笑谈中。']\n",
            "['zh']\n",
            "  4% 63/1500 [00:01<00:23, 61.24it/s]T2S Decoding EOS [114 -> 181]\n",
            "  4% 67/1500 [00:01<00:23, 60.87it/s]\n",
            "0.112\t9.975\t1.102\t0.435\n",
            "实际输入的参考文本: 今天呢我跟大家分享一个关于化妆包的话题。\n",
            "实际输入的目标文本: 滚滚长江东逝水，浪花淘尽英雄。\n",
            "\n",
            "是非成败转头空。\n",
            "\n",
            "青山依旧在，几度夕阳红。\n",
            "\n",
            "白发渔樵江渚上，惯看秋月春风。\n",
            "\n",
            "一壶浊酒喜相逢。\n",
            "\n",
            "古今多少事，都付笑谈中。\n",
            "[]\n",
            "实际输入的目标文本(切句后): 滚滚长江东逝水，浪花淘尽英雄\n",
            "是非成败转头空\n",
            "青山依旧在，几度夕阳红\n",
            "白发渔樵江渚上，惯看秋月春风\n",
            "一壶浊酒喜相逢\n",
            "古今多少事，都付笑谈中\n",
            "['今天呢我跟大家分享一个关于化妆包的话题。']\n",
            "['zh']\n",
            "实际输入的目标文本(每句): 滚滚长江东逝水，浪花淘尽英雄。\n",
            "[]\n",
            "['滚滚长江东逝水，浪花淘尽英雄。']\n",
            "['zh']\n",
            " 11% 160/1500 [00:02<00:21, 62.22it/s]T2S Decoding EOS [114 -> 280]\n",
            " 11% 166/1500 [00:02<00:21, 61.69it/s]\n",
            "实际输入的目标文本(每句): 是非成败转头空。\n",
            "[]\n",
            "['是非成败转头空。']\n",
            "['zh']\n",
            "  4% 56/1500 [00:00<00:22, 64.63it/s]T2S Decoding EOS [114 -> 171]\n",
            "  4% 57/1500 [00:00<00:22, 63.82it/s]\n",
            "实际输入的目标文本(每句): 青山依旧在，几度夕阳红。\n",
            "[]\n",
            "['青山依旧在，几度夕阳红。']\n",
            "['zh']\n",
            "  8% 119/1500 [00:01<00:22, 61.92it/s]T2S Decoding EOS [114 -> 237]\n",
            "  8% 123/1500 [00:02<00:22, 61.24it/s]\n",
            "实际输入的目标文本(每句): 白发渔樵江渚上，惯看秋月春风。\n",
            "[]\n",
            "['白发渔樵江渚上，惯看秋月春风。']\n",
            "['zh']\n",
            "  8% 123/1500 [00:02<00:33, 41.40it/s]T2S Decoding EOS [114 -> 238]\n",
            "  8% 124/1500 [00:02<00:30, 45.37it/s]\n",
            "实际输入的目标文本(每句): 一壶浊酒喜相逢。\n",
            "[]\n",
            "['一壶浊酒喜相逢。']\n",
            "['zh']\n",
            "  3% 51/1500 [00:01<00:25, 57.16it/s]T2S Decoding EOS [114 -> 167]\n",
            "  4% 53/1500 [00:01<00:29, 48.41it/s]\n",
            "实际输入的目标文本(每句): 古今多少事，都付笑谈中。\n",
            "[]\n",
            "['古今多少事，都付笑谈中。']\n",
            "['zh']\n",
            "  5% 70/1500 [00:01<00:23, 62.01it/s]T2S Decoding EOS [114 -> 189]\n",
            "  5% 75/1500 [00:01<00:23, 60.32it/s]\n",
            "0.118\t11.790\t1.244\t0.427\n",
            "实际输入的参考文本: 今天呢我跟大家分享一个关于化妆包的话题。\n",
            "实际输入的目标文本: 滚滚长江东逝水，浪花淘尽英雄。\n",
            "\n",
            "是非成败转头空。\n",
            "\n",
            "青山依旧在，几度夕阳红。\n",
            "[]\n",
            "实际输入的目标文本(切句后): 滚滚长江东逝水，浪花淘尽英雄\n",
            "是非成败转头空\n",
            "青山依旧在，几度夕阳红\n",
            "['今天呢我跟大家分享一个关于化妆包的话题。']\n",
            "['zh']\n",
            "实际输入的目标文本(每句): 滚滚长江东逝水，浪花淘尽英雄。\n",
            "[]\n",
            "['滚滚长江东逝水，浪花淘尽英雄。']\n",
            "['zh']\n",
            "  7% 112/1500 [00:01<00:22, 62.46it/s]T2S Decoding EOS [114 -> 227]\n",
            "  8% 113/1500 [00:01<00:22, 62.40it/s]\n",
            "实际输入的目标文本(每句): 是非成败转头空。\n",
            "[]\n",
            "['是非成败转头空。']\n",
            "['zh']\n",
            "  4% 59/1500 [00:00<00:23, 61.82it/s]T2S Decoding EOS [114 -> 174]\n",
            "  4% 60/1500 [00:01<00:24, 59.07it/s]\n",
            "实际输入的目标文本(每句): 青山依旧在，几度夕阳红。\n",
            "[]\n",
            "['青山依旧在，几度夕阳红。']\n",
            "['zh']\n",
            "  5% 81/1500 [00:01<00:28, 50.43it/s]T2S Decoding EOS [114 -> 200]\n",
            "  6% 86/1500 [00:01<00:25, 55.92it/s]\n",
            "0.123\t3.554\t1.539\t0.671\n",
            "实际输入的参考文本: 今天呢我跟大家分享一个关于化妆包的话题。\n",
            "实际输入的目标文本: 丙辰中秋，欢饮达旦，大醉，作此篇，兼怀子由。\n",
            "\n",
            "明月几时有，把酒问青天。\n",
            "\n",
            "不知天上宫阙，今夕是何年？\n",
            "\n",
            "我欲乘风归去，又恐琼楼玉宇，高处不胜寒。\n",
            "\n",
            "起舞弄清影，何似在人间！\n",
            "\n",
            "转朱阁，低绮户，照无眠。\n",
            "\n",
            "不应有恨，何事长向别时圆？\n",
            "\n",
            "人有悲欢离合，月有阴晴圆缺，\n",
            "\n",
            "此事古难全，但愿人长久，千里共婵娟。\n",
            "[]\n",
            "实际输入的目标文本(切句后): 丙辰中秋，欢饮达旦，大醉，作此篇，兼怀子由\n",
            "明月几时有，把酒问青天\n",
            "不知天上宫阙，今夕是何年？\n",
            "我欲乘风归去，又恐琼楼玉宇，高处不胜寒\n",
            "起舞弄清影，何似在人间！\n",
            "转朱阁，低绮户，照无眠\n",
            "不应有恨，何事长向别时圆？\n",
            "人有悲欢离合，月有阴晴圆缺，\n",
            "此事古难全，但愿人长久，千里共婵娟\n",
            "['今天呢我跟大家分享一个关于化妆包的话题。']\n",
            "['zh']\n",
            "实际输入的目标文本(每句): 丙辰中秋，欢饮达旦，大醉，作此篇，兼怀子由。\n",
            "[]\n",
            "['丙辰中秋，欢饮达旦，大醉，作此篇，兼怀子由。']\n",
            "['zh']\n",
            " 10% 147/1500 [00:02<00:21, 63.21it/s]T2S Decoding EOS [114 -> 267]\n",
            " 10% 153/1500 [00:02<00:21, 62.24it/s]\n",
            "实际输入的目标文本(每句): 明月几时有，把酒问青天。\n",
            "[]\n",
            "['明月几时有，把酒问青天。']\n",
            "['zh']\n",
            "  4% 55/1500 [00:00<00:22, 65.11it/s]T2S Decoding EOS [114 -> 174]\n",
            "  4% 60/1500 [00:00<00:22, 62.75it/s]\n",
            "实际输入的目标文本(每句): 不知天上宫阙，今夕是何年？\n",
            "[]\n",
            "['不知天上宫阙，今夕是何年？']\n",
            "['zh']\n",
            "  7% 98/1500 [00:01<00:22, 62.99it/s]T2S Decoding EOS [114 -> 212]\n",
            "  7% 98/1500 [00:01<00:22, 62.71it/s]\n",
            "实际输入的目标文本(每句): 我欲乘风归去，又恐琼楼玉宇，高处不胜寒。\n",
            "[]\n",
            "['我欲乘风归去，又恐琼楼玉宇，高处不胜寒。']\n",
            "['zh']\n",
            "  7% 109/1500 [00:01<00:22, 62.90it/s]T2S Decoding EOS [114 -> 229]\n",
            "  8% 115/1500 [00:01<00:22, 60.73it/s]\n",
            "实际输入的目标文本(每句): 起舞弄清影，何似在人间！\n",
            "[]\n",
            "['起舞弄清影，何似在人间！']\n",
            "['zh']\n",
            "  6% 84/1500 [00:01<00:23, 61.10it/s]T2S Decoding EOS [114 -> 200]\n",
            "  6% 86/1500 [00:01<00:23, 61.47it/s]\n",
            "实际输入的目标文本(每句): 转朱阁，低绮户，照无眠。\n",
            "[]\n",
            "['转朱阁，低绮户，照无眠。']\n",
            "['zh']\n",
            "  7% 112/1500 [00:02<00:33, 41.15it/s]T2S Decoding EOS [114 -> 226]\n",
            "  7% 112/1500 [00:02<00:32, 42.63it/s]\n",
            "实际输入的目标文本(每句): 不应有恨，何事长向别时圆？\n",
            "[]\n",
            "['不应有恨，何事长向别时圆？']\n",
            "['zh']\n",
            "  6% 93/1500 [00:01<00:22, 62.73it/s]T2S Decoding EOS [114 -> 211]\n",
            "  6% 97/1500 [00:01<00:23, 58.58it/s]\n",
            "实际输入的目标文本(每句): 人有悲欢离合，月有阴晴圆缺，\n",
            "[]\n",
            "['人有悲欢离合，月有阴晴圆缺，']\n",
            "['zh']\n",
            "  6% 96/1500 [00:01<00:22, 61.64it/s]T2S Decoding EOS [114 -> 216]\n",
            "  7% 102/1500 [00:01<00:23, 60.67it/s]\n",
            "实际输入的目标文本(每句): 此事古难全，但愿人长久，千里共婵娟。\n",
            "[]\n",
            "['此事古难全，但愿人长久，千里共婵娟。']\n",
            "['zh']\n",
            "  7% 112/1500 [00:01<00:22, 62.68it/s]T2S Decoding EOS [114 -> 230]\n",
            "  8% 116/1500 [00:01<00:22, 62.72it/s]\n",
            "0.222\t17.541\t1.850\t0.471\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2130, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/GPT-SoVITS/webui.py\", line 786, in <module>\n",
            "    app.queue(concurrency_count=511, max_size=1022).launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2046, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2134, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 49, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:9874 <> https://602a9d46c5414275fa.gradio.live\n",
            "Killing tunnel 0.0.0.0:9872 <> https://b844142b936019583e.gradio.live\n",
            "Killing tunnel 0.0.0.0:9871 <> https://86b4119ec361c81cd1.gradio.live\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!sed -i 's/is_share=False/is_share=True/g' config.py\n",
        "!python webui.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u0kP0eywlHb"
      },
      "source": [
        "## 一键将云盘模型覆盖导入推理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48oPD9qRwr_n"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/GPT-SoVITS/GPT_weights/*\n",
        "!rm -rf /content/GPT-SoVITS/SoVITS_weights/*\n",
        "!cp -r /content/drive/MyDrive/GPT-SoVITS/model/gpt/* /content/GPT-SoVITS/GPT_weights\n",
        "!cp -r /content/drive/MyDrive/GPT-SoVITS/model/sovits/* /content/GPT-SoVITS/SoVITS_weights"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UtOtTFiGZJ-N",
        "hIgovmIrZVAc",
        "66ri0484Yz64",
        "9ZRVt9Kbcrma"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}